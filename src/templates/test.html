<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Live Speech to Text - VOSK Medium</title>
    <script src="https://cdn.socket.io/4.5.0/socket.io.min.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .controls {
            text-align: center;
            margin-bottom: 30px;
        }
        button {
            background: #007bff;
            color: white;
            border: none;
            padding: 15px 30px;
            font-size: 16px;
            border-radius: 5px;
            cursor: pointer;
            margin: 0 10px;
        }
        button:hover {
            background: #0056b3;
        }
        button:disabled {
            background: #6c757d;
            cursor: not-allowed;
        }
        .recording {
            background: #dc3545 !important;
        }
        .status {
            text-align: center;
            margin: 20px 0;
            padding: 10px;
            border-radius: 5px;
        }
        .status.connected {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        .status.disconnected {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
        .transcription {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 5px;
            padding: 20px;
            min-height: 200px;
            font-size: 16px;
            line-height: 1.5;
        }
        .live-indicator {
            display: inline-block;
            width: 10px;
            height: 10px;
            background: #dc3545;
            border-radius: 50%;
            margin-right: 10px;
            animation: blink 1s infinite;
        }
        @keyframes blink {
            0%, 50% { opacity: 1; }
            51%, 100% { opacity: 0; }
        }
        .debug {
            background: #e9ecef;
            border: 1px solid #ced4da;
            border-radius: 5px;
            padding: 10px;
            margin: 10px 0;
            font-family: monospace;
            font-size: 12px;
            max-height: 150px;
            overflow-y: auto;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>🎤 Live Speech to Text - VOSK Medium Model</h1>
        
        <div class="status" id="status">
            Connecting to server...
        </div>

        <div class="controls">
            <button id="startBtn">Start Recording</button>
            <button id="stopBtn" disabled>Stop Recording</button>
            <button id="clearBtn">Clear Text</button>
        </div>

        <div id="recordingIndicator" style="display: none; text-align: center; margin-bottom: 20px;">
            <span class="live-indicator"></span>
            <strong>Recording... Speak now!</strong>
        </div>

        <h3>Live Transcription:</h3>
        <div class="transcription" id="transcription">
            <em>Click "Start Recording" and begin speaking...</em>
        </div>

        <h4>Debug Info:</h4>
        <div class="debug" id="debug">
            Debug information will appear here...
        </div>
    </div>

    <script>
        const socket = io();
        let mediaRecorder;
        let isRecording = false;
        let chunkCount = 0;
        let fullTranscription = "";

        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const clearBtn = document.getElementById('clearBtn');
        const status = document.getElementById('status');
        const transcription = document.getElementById('transcription');
        const recordingIndicator = document.getElementById('recordingIndicator');
        const debug = document.getElementById('debug');

        function addDebug(message) {
            const time = new Date().toLocaleTimeString();
            debug.innerHTML += `[${time}] ${message}<br>`;
            debug.scrollTop = debug.scrollHeight;
            console.log(message);
        }

        // Socket events
        socket.on('connect', () => {
            status.textContent = 'Connected to VOSK ✅';
            status.className = 'status connected';
            addDebug('Connected to VOSK transcription service');
        });

        socket.on('disconnect', () => {
            status.textContent = 'Disconnected ❌';
            status.className = 'status disconnected';
            addDebug('Disconnected from server');
        });

        socket.on('transcription', (data) => {
            addDebug(`Received: "${data.text}"`);
            if (data.text.trim()) {
                if (fullTranscription === "" || transcription.textContent.includes('Click "Start Recording"')) {
                    fullTranscription = data.text;
                } else {
                    fullTranscription += " " + data.text;
                }
                transcription.textContent = fullTranscription;
                transcription.scrollTop = transcription.scrollHeight;
            }
        });

        socket.on('error', (data) => {
            addDebug(`Error: ${data.message}`);
            status.textContent = 'Error: ' + data.message;
            status.className = 'status disconnected';
        });

        socket.on('status', (data) => {
            addDebug(`Status: ${data.message}`);
        });

        // Audio recording
        startBtn.addEventListener('click', async () => {
            try {
                addDebug('Requesting microphone...');
                
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 16000,  // Match VOSK requirement
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    } 
                });
                
                addDebug('Microphone granted');
                
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        chunkCount++;
                        addDebug(`Chunk #${chunkCount}, size: ${event.data.size} bytes`);
                        
                        // Send raw audio data directly
                        const reader = new FileReader();
                        reader.onload = () => {
                            const arrayBuffer = reader.result;
                            addDebug(`Sending audio data: ${arrayBuffer.byteLength} bytes`);
                            socket.emit('audio_chunk', { audio: arrayBuffer });
                        };
                        reader.readAsArrayBuffer(event.data);
                    }
                };

                mediaRecorder.start(3000); // 3-second chunks
                isRecording = true;
                chunkCount = 0;
                fullTranscription = "";
                
                startBtn.disabled = true;
                stopBtn.disabled = false;
                startBtn.textContent = 'Recording...';
                startBtn.classList.add('recording');
                recordingIndicator.style.display = 'block';
                
                addDebug('Recording started with VOSK medium model');

            } catch (err) {
                addDebug(`Microphone error: ${err.message}`);
                alert('Microphone access required. Please allow and use HTTPS.');
            }
        });

        stopBtn.addEventListener('click', () => {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                isRecording = false;
                
                startBtn.disabled = false;
                stopBtn.disabled = true;
                startBtn.textContent = 'Start Recording';
                startBtn.classList.remove('recording');
                recordingIndicator.style.display = 'none';
                
                addDebug('Recording stopped');
            }
        });

        clearBtn.addEventListener('click', () => {
            transcription.innerHTML = '<em>Click "Start Recording" and begin speaking...</em>';
            debug.innerHTML = 'Debug information will appear here...';
            fullTranscription = "";
            addDebug('Interface cleared');
        });

        addDebug('Page loaded, ready for VOSK medium model transcription');
    </script>
</body>
</html>
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                isRecording = false;
                
                startBtn.disabled = false;
                stopBtn.disabled = true;
                startBtn.textContent = 'Start Recording';
                startBtn.classList.remove('recording');
                recordingIndicator.style.display = 'none';
                
                addDebug('Recording stopped');
            }
        });

        clearBtn.addEventListener('click', () => {
            transcription.innerHTML = '<em>Click "Start Recording" and begin speaking...</em>';
            debug.innerHTML = 'Debug information will appear here...';
            fullTranscription = "";
            addDebug('Interface cleared');
        });

        // Test connection on page load
        addDebug('Page loaded, testing WebSocket connection...');
    </script>
</body>
</html>
